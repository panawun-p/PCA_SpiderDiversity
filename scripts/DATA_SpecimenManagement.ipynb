{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATA_SpecimenManagement.ipynb\n",
        "Created by: `Panawun P.` <br>\n",
        "Created on: `2025-10-22`<br>\n",
        "Last editted: `2025-10-26`<br>\n",
        "<br>\n",
        "Manage specimen data in raw data file, create specimen ID from identification data, auto manage specimen photo album and add link to data file.\n",
        "- Data has to be sorted by Date > Time before running the script\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dWzmERaZ0rEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting and Init"
      ],
      "metadata": {
        "id": "wHU1LauW3AmL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcSFt_JK0Nks"
      },
      "outputs": [],
      "source": [
        "RAW_DATA_SHEET_ID = '[GOOGLE DRIVE FILE ID]'\n",
        "\n",
        "SPECIMEN_SHEET_NAME = 'SpecimenData'\n",
        "SPECIMEN_IMG_FOLDER_ID = '[GOOGLE DRIVE FOLDER ID]'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timezone\n",
        "from zoneinfo import ZoneInfo\n",
        "import pytz\n",
        "import time\n",
        "\n",
        "# OAuth for gspread\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "import requests\n",
        "import gspread\n",
        "\n",
        "from googleapiclient.errors import HttpError\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "gc = gspread.authorize(creds) # Authorize with OAuth"
      ],
      "metadata": {
        "id": "oVV8AogN5HiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ect settings\n",
        "RUNNING_NO_LEN = 3 # Numbers of digits for running numbers\n",
        "IMG_NO_LEN = 2"
      ],
      "metadata": {
        "id": "dQ2xrKSAGY2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "UTnsLT163uwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fn: open_datasheet\n",
        "Open spreadsheet and return spreadsheet ID, worksheet ID, and data as variable"
      ],
      "metadata": {
        "id": "AQW6TK0362t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def open_datasheet():\n",
        "    # Read data\n",
        "    sheet_name = SPECIMEN_SHEET_NAME\n",
        "    sheet_url = f'https://docs.google.com/spreadsheets/d/{RAW_DATA_SHEET_ID}/'\n",
        "\n",
        "    spreadsheet = gc.open_by_url(sheet_url)\n",
        "    worksheet = spreadsheet.worksheet(sheet_name)\n",
        "    data = worksheet.get_all_values()\n",
        "\n",
        "    return spreadsheet, worksheet, data"
      ],
      "metadata": {
        "id": "1DnK16-y5Z_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fn: generate_specimen_id"
      ],
      "metadata": {
        "id": "OTiPjJBH7Ok0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_specimen_id(row_info, row, taxa_count):\n",
        "    # If row has all info to generate ID\n",
        "    if row[row_info['transect_id']] and row[row_info['col_method']] and row[row_info['taxa_fam']]:\n",
        "        transect_code = row[row_info['transect_id']][-5:].replace('-', '').upper()\n",
        "        method_code = row[row_info['col_method']][:2].upper()\n",
        "        family_code = row[row_info['taxa_fam']][:2].upper()\n",
        "\n",
        "        # Running number for family\n",
        "        if family_code not in taxa_count:\n",
        "            taxa_count[family_code] = 1\n",
        "        else:\n",
        "            taxa_count[family_code] += 1\n",
        "        running_no = f'{taxa_count[family_code]:0{RUNNING_NO_LEN}d}'\n",
        "\n",
        "        row[row_info['specimen_id']] = f'{transect_code}{method_code}-{family_code}{running_no}'\n",
        "        # print(specimen_id)\n",
        "        return row\n",
        "\n",
        "    else: # Skip rows with incomplete info\n",
        "        return False"
      ],
      "metadata": {
        "id": "xn2mD_gP6wY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fn: create_specimen_img_folder"
      ],
      "metadata": {
        "id": "l4MPB9hLCXWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_specimen_img_folder(specimen_id):\n",
        "    folder_metadata = {'name': specimen_id,\n",
        "                       'mimeType': 'application/vnd.google-apps.folder',\n",
        "                       'parents': [SPECIMEN_IMG_FOLDER_ID]}\n",
        "\n",
        "    # Check if folder already exist, return folder id\n",
        "    query = f\"name='{folder_metadata['name']}' and mimeType='{folder_metadata['mimeType']}' and '{SPECIMEN_IMG_FOLDER_ID}' in parents and trashed =false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "    items = results.get('files', [])\n",
        "    if items: return items[0]['id']\n",
        "\n",
        "    # If folder does not exist, attempt to create folder\n",
        "    try:\n",
        "        print(\"Creating image folder...\")\n",
        "        folder = drive_service.files().create(body=folder_metadata, fields='id').execute()\n",
        "        return folder['id']\n",
        "    except HttpError as error:\n",
        "        print(f\"An error occurred: {error}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "iA6EwB8HIf7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fn: add_info_to_sheet"
      ],
      "metadata": {
        "id": "sLpdOpCFV0wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_info_to_sheet(worksheet, row_info, row_i, specimen_id, folder_id):\n",
        "    # Convert number to letter\n",
        "    int_to_letter = lambda x:\"\" if x==0 else int_to_letter((x-1)//26)+chr((x-1)%26+ord(\"A\"))\n",
        "\n",
        "    # Update sheet with specimen id\n",
        "    cell_col = cell_col = row_info['specimen_id'] # Determine cell location\n",
        "    cell_location = f'{int_to_letter(cell_col+1)}{row_i+1}'\n",
        "    worksheet.update(cell_location, [[specimen_id]], value_input_option='USER_ENTERED')\n",
        "\n",
        "    # Update sheet with folder link\n",
        "    cell_col = cell_col = row_info['specimen_img'] # Determine cell location\n",
        "    cell_location = f'{int_to_letter(cell_col+1)}{row_i+1}'\n",
        "    drive_folder_link = f'https://drive.google.com/drive/folders/{folder_id}'\n",
        "    link_formula = f'=HYPERLINK(\"{drive_folder_link}\", \"{specimen_id}\")'\n",
        "    worksheet.update(cell_location, [[link_formula]], value_input_option='USER_ENTERED')"
      ],
      "metadata": {
        "id": "3g8AS_fnV9qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fn: parse_img_time"
      ],
      "metadata": {
        "id": "Xt0i_777E3D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_img_time(img_list):\n",
        "    converted_img_list = []\n",
        "    for img_i, img_info in enumerate(img_list):\n",
        "        converted_img_list.append(img_info)\n",
        "        # Parse date and time from the image assume Pixel photo file format\n",
        "        # eg. \"PXL_20251020_234817441.jpg\" - Note that time in file name is always in UTM\n",
        "        datetime_string = img_info['name'][4:-9]\n",
        "        datetime_format = '%Y%m%d_%H%M'\n",
        "        img_info['datetime'] = datetime.strptime(datetime_string, datetime_format)\n",
        "        img_info['datetime'] = img_info['datetime'].replace(tzinfo=timezone.utc) # Make datetime obj UTC-aware\n",
        "\n",
        "        # Convert from UTC to Canada/Eastern\n",
        "        converted_img_list[img_i]['datetime'] = img_info['datetime'].astimezone(ZoneInfo('Canada/Eastern'))\n",
        "\n",
        "    # print(converted_img_list[0]['datetime'])\n",
        "\n",
        "    return converted_img_list"
      ],
      "metadata": {
        "id": "9stKVYvME_h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fn: get_img_list"
      ],
      "metadata": {
        "id": "Vpu8Ng9gCQSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_list(folder_id):\n",
        "    query = f\"'{folder_id}' in parents and trashed =false\"\n",
        "    file_list = drive_service.files().list(q=query,\n",
        "                                        fields='nextPageToken, files(id, name, mimeType)').execute()\n",
        "    img_list = file_list.get('files', [])\n",
        "\n",
        "    img_list = [file_info for file_info in img_list if 'image/' in file_info['mimeType']]\n",
        "    img_list = parse_img_time(img_list)\n",
        "\n",
        "    return img_list"
      ],
      "metadata": {
        "id": "yiB5Egt_CVnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Block"
      ],
      "metadata": {
        "id": "wj1u2hRP3yAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fn: update_sheet"
      ],
      "metadata": {
        "id": "EyiduFZ7904w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_sheet():\n",
        "    taxa_count = {} # To keep running numbers/count for specimen id\n",
        "    unsort_img_list = get_img_list(SPECIMEN_IMG_FOLDER_ID) # get a list of unsorted imgs\n",
        "    print(f\"Total {len(unsort_img_list)} images to upload.\")\n",
        "\n",
        "    for row_i, row in enumerate(data):\n",
        "        if row_i == 0: # Header row\n",
        "            row_info = {'id_date': row.index('ID DATE'),\n",
        "                        'id_time': row.index('ID TIME'),\n",
        "                        'specimen_id': row.index('SPECIMEN ID'),\n",
        "                        'specimen_img': row.index('SPECIMEN IMAGES'),\n",
        "                        'col_method': row.index('METHOD'),\n",
        "                        'transect_id': row.index('TRANSECT ID'),\n",
        "                        'taxa_fam': row.index('FAMILY'),\n",
        "                        }\n",
        "        else:\n",
        "            # Generate specimen id, create img folder, and add img folder link to sheet\n",
        "            row = generate_specimen_id(row_info, row, taxa_count)\n",
        "\n",
        "            if row: # Check that specimen ID is generated (data not missing)\n",
        "                print(f\"Processing specimen: {row[row_info['specimen_id']]}\")\n",
        "                folder_id = create_specimen_img_folder(row[row_info['specimen_id']])\n",
        "\n",
        "                # Add link to img folder to sheet\n",
        "                add_info_to_sheet(worksheet, row_info, row_i, row[row_info['specimen_id']], folder_id)\n",
        "            else:\n",
        "                continue # Skip further processing on the row if data missing\n",
        "\n",
        "            # Go through images, uploaded to the folder, sort into folder, and rename files\n",
        "            datetime_format = '%Y-%m-%d %H:%M'\n",
        "            id_datetime = f\"{row[row_info['id_date']]} {row[row_info['id_time']]}\"\n",
        "            next_id_datetime = f\"{data[row_i+1][row_info['id_date']]} {data[row_i+1][row_info['id_time']]}\"\n",
        "\n",
        "            # Convert to datetime obj\n",
        "            id_datetime = datetime.strptime(id_datetime, datetime_format)\n",
        "            if next_id_datetime == \" \": # If next row is empty then use current datetime\n",
        "                next_id_datetime = datetime.now()\n",
        "            else:\n",
        "                next_id_datetime = datetime.strptime(next_id_datetime, datetime_format)\n",
        "            # print(f\"id_datetime: {id_datetime}, next_id_datetime: {next_id_datetime}\")\n",
        "\n",
        "            # Reformat to timezone-aware datetime obj\n",
        "            id_datetime = pytz.timezone('Canada/Eastern').localize(id_datetime)\n",
        "            next_id_datetime = pytz.timezone('Canada/Eastern').localize(next_id_datetime)\n",
        "            print(f\"ID Time: {id_datetime} to {next_id_datetime}\")\n",
        "\n",
        "            # Get list of images assoc with specimen ID time\n",
        "            specimen_img_list = [img_info for img_info in unsort_img_list if id_datetime <= img_info['datetime'] < next_id_datetime]\n",
        "\n",
        "            if specimen_img_list:\n",
        "                print(f\"Uploading {len(specimen_img_list)} specimen images...\")\n",
        "                # Rename images and move to specimen image folder\n",
        "                for img_i, img_info in enumerate(specimen_img_list):\n",
        "                    img_running_no = f'{img_i+1:0{IMG_NO_LEN}d}'\n",
        "                    name_metadata = {'name': f\"{row[row_info['specimen_id']]}_{img_running_no}\"}\n",
        "\n",
        "                    updated_file = drive_service.files().update(fileId=img_info['id'],\n",
        "                                                                body=name_metadata,\n",
        "                                                                addParents=folder_id,\n",
        "                                                                removeParents=SPECIMEN_IMG_FOLDER_ID,\n",
        "                                                                fields='id, name'\n",
        "                                                                ).execute()\n",
        "\n",
        "                    time.sleep(1)"
      ],
      "metadata": {
        "id": "FhH7j9VM9a7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spreadsheet, worksheet, data = open_datasheet()\n",
        "\n",
        "update_sheet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQKe1kv26RoR",
        "outputId": "3a429754-30ba-4034-fc46-72143b82f70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 35 images to upload.\n",
            "Processing specimen: R02DR-TH001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3513627340.py:8: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  worksheet.update(cell_location, [[specimen_id]], value_input_option='USER_ENTERED')\n",
            "/tmp/ipython-input-3513627340.py:15: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  worksheet.update(cell_location, [[link_formula]], value_input_option='USER_ENTERED')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID Time: 2025-10-07 23:15:00-04:00 to 2025-10-07 23:58:00-04:00\n",
            "Processing specimen: R02DR-CL001\n",
            "ID Time: 2025-10-07 23:58:00-04:00 to 2025-10-09 19:44:00-04:00\n",
            "Processing specimen: R02DR-SA001\n",
            "ID Time: 2025-10-09 19:44:00-04:00 to 2025-10-09 21:02:00-04:00\n",
            "Processing specimen: R02DR-TE001\n",
            "ID Time: 2025-10-09 21:02:00-04:00 to 2025-10-09 21:50:00-04:00\n",
            "Processing specimen: R02DR-TE002\n",
            "ID Time: 2025-10-09 21:50:00-04:00 to 2025-10-09 23:24:00-04:00\n",
            "Processing specimen: M02DR-TH002\n",
            "ID Time: 2025-10-09 23:24:00-04:00 to 2025-10-09 23:57:00-04:00\n",
            "Processing specimen: M02DR-TE003\n",
            "ID Time: 2025-10-09 23:57:00-04:00 to 2025-10-10 00:09:00-04:00\n",
            "Processing specimen: M02DR-TE004\n",
            "ID Time: 2025-10-10 00:09:00-04:00 to 2025-10-20 10:15:00-04:00\n",
            "Processing specimen: R03DR-SA002\n",
            "ID Time: 2025-10-20 10:15:00-04:00 to 2025-10-20 10:20:00-04:00\n",
            "Processing specimen: R03DR-TE005\n",
            "ID Time: 2025-10-20 10:20:00-04:00 to 2025-10-20 10:25:00-04:00\n",
            "Processing specimen: R03DR-DI001\n",
            "ID Time: 2025-10-20 10:25:00-04:00 to 2025-10-20 15:03:00-04:00\n",
            "Processing specimen: R03DR-PH001\n",
            "ID Time: 2025-10-20 15:03:00-04:00 to 2025-10-20 16:04:00-04:00\n",
            "Processing specimen: R08DR-PH002\n",
            "ID Time: 2025-10-20 16:04:00-04:00 to 2025-10-20 16:15:00-04:00\n",
            "Processing specimen: R08DR-DI002\n",
            "ID Time: 2025-10-20 16:15:00-04:00 to 2025-10-20 16:20:00-04:00\n",
            "Processing specimen: R08DR-LI001\n",
            "ID Time: 2025-10-20 16:20:00-04:00 to 2025-10-20 16:43:00-04:00\n",
            "Processing specimen: R07DR-UL001\n",
            "ID Time: 2025-10-20 16:43:00-04:00 to 2025-10-20 17:30:00-04:00\n",
            "Processing specimen: R07DR-PH003\n",
            "ID Time: 2025-10-20 17:30:00-04:00 to 2025-10-20 18:36:00-04:00\n",
            "Processing specimen: M01DR-AR001\n",
            "ID Time: 2025-10-20 18:36:00-04:00 to 2025-10-20 18:56:00-04:00\n",
            "Processing specimen: M01DR-DI003\n",
            "ID Time: 2025-10-20 18:56:00-04:00 to 2025-10-20 19:07:00-04:00\n",
            "Processing specimen: M01DR-DI004\n",
            "ID Time: 2025-10-20 19:07:00-04:00 to 2025-10-20 19:13:00-04:00\n",
            "Processing specimen: M01DR-TE006\n",
            "ID Time: 2025-10-20 19:13:00-04:00 to 2025-10-20 19:26:00-04:00\n",
            "Processing specimen: R04DR-TH003\n",
            "ID Time: 2025-10-20 19:26:00-04:00 to 2025-10-20 19:35:00-04:00\n",
            "Processing specimen: R04DR-PH004\n",
            "ID Time: 2025-10-20 19:35:00-04:00 to 2025-10-20 19:43:00-04:00\n",
            "Processing specimen: R04DR-DI005\n",
            "ID Time: 2025-10-20 19:43:00-04:00 to 2025-10-20 20:01:00-04:00\n",
            "Processing specimen: R04DR-AR002\n",
            "ID Time: 2025-10-20 20:01:00-04:00 to 2025-10-20 20:31:00-04:00\n",
            "Processing specimen: M07DR-TE007\n",
            "ID Time: 2025-10-20 20:31:00-04:00 to 2025-10-20 20:36:00-04:00\n",
            "Processing specimen: M07DR-TE008\n",
            "ID Time: 2025-10-20 20:36:00-04:00 to 2025-10-20 20:40:00-04:00\n",
            "Processing specimen: M07DR-TE009\n",
            "ID Time: 2025-10-20 20:40:00-04:00 to 2025-10-20 20:46:00-04:00\n",
            "Processing specimen: M07DR-TE010\n",
            "ID Time: 2025-10-20 20:46:00-04:00 to 2025-10-21 18:25:00-04:00\n",
            "Processing specimen: M06DR-PH005\n",
            "ID Time: 2025-10-21 18:25:00-04:00 to 2025-10-21 18:28:00-04:00\n",
            "Processing specimen: M06DR-PH006\n",
            "ID Time: 2025-10-21 18:28:00-04:00 to 2025-10-21 19:40:00-04:00\n",
            "Processing specimen: M06DR-PH007\n",
            "ID Time: 2025-10-21 19:40:00-04:00 to 2025-10-21 19:48:00-04:00\n",
            "Processing specimen: M06DR-PH008\n",
            "ID Time: 2025-10-21 19:48:00-04:00 to 2025-10-21 20:20:00-04:00\n",
            "Processing specimen: M06DR-LI002\n",
            "ID Time: 2025-10-21 20:20:00-04:00 to 2025-10-21 20:43:00-04:00\n",
            "Processing specimen: M06DR-LI003\n",
            "ID Time: 2025-10-21 20:43:00-04:00 to 2025-10-21 21:00:00-04:00\n",
            "Processing specimen: M06DR-CL002\n",
            "ID Time: 2025-10-21 21:00:00-04:00 to 2025-10-21 21:14:00-04:00\n",
            "Processing specimen: M06DR-LI004\n",
            "ID Time: 2025-10-21 21:14:00-04:00 to 2025-10-21 23:22:00-04:00\n",
            "Processing specimen: R06DR-LI005\n",
            "ID Time: 2025-10-21 23:22:00-04:00 to 2025-10-21 23:42:00-04:00\n",
            "Processing specimen: R06DR-DI006\n",
            "ID Time: 2025-10-21 23:42:00-04:00 to 2025-10-21 23:45:00-04:00\n",
            "Processing specimen: R06DR-TH004\n",
            "ID Time: 2025-10-21 23:45:00-04:00 to 2025-10-21 23:50:00-04:00\n",
            "Processing specimen: R06DR-LI006\n",
            "ID Time: 2025-10-21 23:50:00-04:00 to 2025-10-22 00:00:00-04:00\n",
            "Processing specimen: R06DR-LI007\n",
            "ID Time: 2025-10-22 00:00:00-04:00 to 2025-10-22 00:30:00-04:00\n",
            "Processing specimen: R06DR-AR003\n",
            "ID Time: 2025-10-22 00:30:00-04:00 to 2025-10-24 15:51:00-04:00\n",
            "Processing specimen: R01DR-TH005\n",
            "ID Time: 2025-10-24 15:51:00-04:00 to 2025-10-24 16:01:00-04:00\n",
            "Uploading 5 specimen images...\n",
            "Processing specimen: R01DR-TH006\n",
            "ID Time: 2025-10-24 16:01:00-04:00 to 2025-10-24 16:07:00-04:00\n",
            "Uploading 4 specimen images...\n",
            "Processing specimen: R01DR-CL003\n",
            "ID Time: 2025-10-24 16:07:00-04:00 to 2025-10-24 16:14:00-04:00\n",
            "Uploading 8 specimen images...\n",
            "Processing specimen: R01DR-TE011\n",
            "ID Time: 2025-10-24 16:14:00-04:00 to 2025-10-24 16:23:00-04:00\n",
            "Uploading 2 specimen images...\n",
            "Processing specimen: R01DR-LI008\n",
            "ID Time: 2025-10-24 16:23:00-04:00 to 2025-10-24 16:30:00-04:00\n",
            "Uploading 3 specimen images...\n",
            "Processing specimen: R01DR-TE012\n",
            "ID Time: 2025-10-24 16:30:00-04:00 to 2025-10-24 16:39:00-04:00\n",
            "Uploading 4 specimen images...\n",
            "Processing specimen: R01DR-DI007\n",
            "ID Time: 2025-10-24 16:39:00-04:00 to 2025-10-24 16:45:00-04:00\n",
            "Uploading 5 specimen images...\n",
            "Processing specimen: R01DR-PH009\n",
            "ID Time: 2025-10-24 16:45:00-04:00 to 2025-10-24 16:54:00-04:00\n",
            "Uploading 2 specimen images...\n",
            "Processing specimen: R01DR-LI009\n",
            "ID Time: 2025-10-24 16:54:00-04:00 to 2025-10-26 22:30:00-04:00\n",
            "Uploading 2 specimen images...\n",
            "Processing specimen: M03DR-TE013\n",
            "ID Time: 2025-10-26 22:30:00-04:00 to 2025-10-26 22:50:00-04:00\n",
            "Processing specimen: M03DR-TE014\n",
            "ID Time: 2025-10-26 22:50:00-04:00 to 2025-10-26 22:57:00-04:00\n",
            "Processing specimen: M03DR-TE015\n",
            "ID Time: 2025-10-26 22:57:00-04:00 to 2025-10-26 23:04:00-04:00\n",
            "Processing specimen: M03DR-TE016\n",
            "ID Time: 2025-10-26 23:04:00-04:00 to 2025-10-26 23:08:00-04:00\n",
            "Processing specimen: M03DR-TH007\n",
            "ID Time: 2025-10-26 23:08:00-04:00 to 2025-10-26 23:18:00-04:00\n",
            "Processing specimen: M03DR-SA003\n",
            "ID Time: 2025-10-26 23:18:00-04:00 to 2025-10-26 23:23:00-04:00\n",
            "Processing specimen: M03DR-SA004\n",
            "ID Time: 2025-10-26 23:23:00-04:00 to 2025-10-27 04:41:18.444529-04:00\n"
          ]
        }
      ]
    }
  ]
}